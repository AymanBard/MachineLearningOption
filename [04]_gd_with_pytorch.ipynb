{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AymanBard/MachineLearningOption/blob/main/%5B04%5D_gd_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie A : descente de gradient pour fonction univariable"
      ],
      "metadata": {
        "id": "r2Vdq1k42Qhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Soit la fonction $f:\\mathbb{R}↦\\mathbb{R}$ telle que $f(x) =(x+1)^2$."
      ],
      "metadata": {
        "id": "eYjdcpr12TPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return (x + 1) ** 2"
      ],
      "metadata": {
        "id": "onRQF-J52CoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On veut trouver $x^*\\in\\mathbb{R}$ tel que $x^* = \\arg\\min_{x\\in\\mathbb{R}}f(x)$ par l'algorithme de descente de gradient."
      ],
      "metadata": {
        "id": "IlOLeIyO24d-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercices\n"
      ],
      "metadata": {
        "id": "h5P4sDrc3vII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.\n",
        "Compléter la fonction Python ci-dessous, qui pour $x\\in\\mathbb{R}$ retourne $f'(x)$, la dérivée de $f$ en $x$."
      ],
      "metadata": {
        "id": "z7mwFNXQ5Coj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def derivee_f(x):\n",
        "  return ?"
      ],
      "metadata": {
        "id": "GjfKii_F23up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.\n",
        "Programmer la descente de gradient en utilisant la fonction `derivee_f` et en vous aidant du bout de code ci-dessous. S'assurer que $x$ converge bien vers $x^*$."
      ],
      "metadata": {
        "id": "yCYcVwRZ50Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1\n",
        "x = 1\n",
        "# descente de gradient\n",
        "for k in range(100):\n",
        "  x = ?\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "id": "oVve8VoP6sWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie B : calcul automatique de dérivées avec PyTorch"
      ],
      "metadata": {
        "id": "Hrw6g7z58b9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va refaire maintenant cette même descente de gradient en utilisant la librairie `PyTorch`. L'utilité principale de `PyTorch` est d'automatiser le calcul des dérivées de fonctions réelles. Voici ci-dessous un exemple d'utilisation, qui calcule $f'(1)$ pour la fonction $f$ définie plus haut."
      ],
      "metadata": {
        "id": "Igq6hCHO61GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # on import la librairie pytorch\n",
        "\n",
        "\n",
        "# on crée une variable x initialisée à 1 et on indique à pytorch qu'on va\n",
        "# calculer des dérivées par rapport à cette variable en passant requires_grad=True\n",
        "x = torch.tensor(1., requires_grad=True)\n",
        "\n",
        "# on calcule f(x) sans modification de la fonction f définie en Partie A\n",
        "y = f(x)\n",
        "\n",
        "# on met à zéro le champ dérivée (.grad) de la variable x. Il est impératif\n",
        "# de faire cela avant de demander à pytorch de calculer la dériviée\n",
        "# car la valeur de la dérivée est ajoutée au champ .grad\n",
        "x.grad = None\n",
        "\n",
        "# on demande à pytorch de calculer la dérivée de y. Il calculera ainsi la\n",
        "# dérivée de y par rapport à toute variable qui intervient dans le calcul de y\n",
        "# et pour qui 'requires_grad' est à 'True'\n",
        "y.backward()\n",
        "\n",
        "# on retrouve de façon automatique cette dérivée dans x.grad\n",
        "print(x.grad)\n"
      ],
      "metadata": {
        "id": "gAArnvH88hQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercices"
      ],
      "metadata": {
        "id": "e4jyCcNi-VXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.\n",
        "\n",
        "Calculer en utilisant `PyTorch` $f'(2)$ puis comparer avec la valeur retournée par la fonction `derivee_f` de la Partie A."
      ],
      "metadata": {
        "id": "Mk-c_X3Q-iET"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0dJdpFAz66RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.\n",
        "Écrire en `Python` la fonction $g(x) = x^3$, puis utiliser `PyTorch` pour calculer $g'(3)$. Est-ce que cela correspond au résultat attendu?"
      ],
      "metadata": {
        "id": "ZVKp3V4L_iCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.\n",
        "Coder la descente de gradient en utilisant `PyTorch` pour le calcul de la dérivée. Vérifier que $x$ converge bien vers $x^*$."
      ],
      "metadata": {
        "id": "v093hPebAI2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "alpha = 0.1\n",
        "\n",
        "# descente de gradient avec pytorch\n",
        "x = ? # créer la variable x\n",
        "for k in range(100):\n",
        "  # Mettre le gradient de x à zero\n",
        "  # Calculer f(x) et sa dérivée\n",
        "  x.data = ? # MAJ suivant la descente de gradient\n",
        "\n",
        "print(x)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "id": "uZUvnhA1_gZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie C : régression linéaire avec Pytorch"
      ],
      "metadata": {
        "id": "F_NqWzZTqifa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercices"
      ],
      "metadata": {
        "id": "yRNVhha91LIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.\n",
        "Coder la régression linéaire par descente de gradient avec Pytorch sur les données `Diabetes` de [scikit-learn](https://scikit-learn.org/stable/datasets/toy_dataset.html)."
      ],
      "metadata": {
        "id": "_uyr_Ftvqx5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "data = load_diabetes()\n",
        "data.keys()\n",
        "\n",
        "data_x = torch.tensor(data.data, dtype=torch.float)"
      ],
      "metadata": {
        "id": "4Yz4U6lcycYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_x"
      ],
      "metadata": {
        "id": "MPPloLGwMFW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.\n",
        "Pour les poids du modèle appris, calculer le score $R^2 = 1 - \\frac{\\sum_k (f(x_k) - y_k)^2}{\\sum_k(\\bar{y} - y_k)^2}$."
      ],
      "metadata": {
        "id": "9L0TIIZwyhSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.\n",
        "Inspecter le vecteur de poids du modèle linéaire et proposer une interprétation de la relation entre données en entrée et données de supervision"
      ],
      "metadata": {
        "id": "RJScaqgyyvh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie D : classification binaire avec PyTorch"
      ],
      "metadata": {
        "id": "Dv0P5lQHCOez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On commence par charger les données `iris`."
      ],
      "metadata": {
        "id": "GhxnPrxp0Gps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Données\n",
        "donnees = datasets.load_iris()\n",
        "filtre = donnees['target'] != 2  # Initialement le jeu de données contient une troisième classe, Iris-Virginica, qu'on ignore\n",
        "attributs = torch.tensor(donnees['data'][filtre, :2]).float()  # Initialement le jeu de données contient deux autres attributs, longueur et largeur de la pétale, qu'on ignore\n",
        "classes = torch.tensor(donnees['target'][filtre])\n",
        "classes[classes == 0] = -1  # On remplace la classe 0 par -1\n",
        "pos_class = classes == 1\n",
        "\n",
        "# Poids neurone formel\n",
        "w = torch.randn(2).requires_grad_(True)\n",
        "b = torch.randn(1)[0].requires_grad_(True)"
      ],
      "metadata": {
        "id": "1WuMj2Sp0hYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichage\n",
        "plt.plot(attributs[~pos_class, 0], attributs[~pos_class, 1], '*b')\n",
        "plt.plot(attributs[pos_class, 0], attributs[pos_class, 1], '*r')\n",
        "o = torch.arange(attributs[:, 0].min() - 1, attributs[:, 0].max() + 1, .1)\n",
        "a = -(w[0] * o + b) / w[1]\n",
        "plt.plot(o, a.detach(), '-g')\n",
        "plt.legend(['Iris Setosa', 'Iris Versicolor', 'Neurone formel'])\n",
        "plt.xlabel('Longueur sépale')\n",
        "plt.ylabel('Largeur sépale')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6scqF1hdCuG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercices"
      ],
      "metadata": {
        "id": "1fCrHspoDpgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.\n",
        "Soit la fonction ci-dessous qui calcule $w\\cdot x + b$"
      ],
      "metadata": {
        "id": "TiGbckqnDstY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fonction_lineaire(w, b, x):\n",
        "  return torch.dot(w, x) + b"
      ],
      "metadata": {
        "id": "TTbi0jKo2fLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En utilisant la fonction `fonction_lineaire`, calculer la fonction de coût $\\ell(w, b, x, y)$ qui est égale à 0 si le neurone formel prédit la classe $y$ pour la donnée $x$, et $-y (w\\cdot x + b)$ sinon"
      ],
      "metadata": {
        "id": "Vvrr0qRdD9PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fonction_cout_l(w, b, x, y):\n",
        "  pass"
      ],
      "metadata": {
        "id": "uRLSuwsu2tmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.\n",
        "En utilisant la fonction `fonction_cout_l`, compléter la fonction `somme_fonction_cout(w, b, X, Y)` ci-dessous qui calcule la somme $\\sum_{(x_i, y_i)\\in(X, Y)} \\ell(w, b, x_i, y_i)$ pour toutes les données $(x_i, y_i)$ de $(X, Y)$"
      ],
      "metadata": {
        "id": "lHthxaJHFeDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def somme_fonction_cout(w, b, X, Y):\n",
        "  'A_COMPLETER'"
      ],
      "metadata": {
        "id": "1I4IQsZNFAP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vérifier que la fonction de coût retourne une valeur $> 0$ avant apprentissage de $w$ et $b$ pour la classification des données `Iris`"
      ],
      "metadata": {
        "id": "K6usrAhQGvkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "somme_fonction_cout(w, b, attributs, classes)"
      ],
      "metadata": {
        "id": "13vHKDxtG7wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.\n",
        "Compléter le code ci-dessous qui apprend les poids $w$ et $b$ du neurone formel pour la classification binaire des données `Iris`. Augmenter le nombre d'itérations jusqu'à ce que la fonction de coût soit nulle (i.e. toutes les données sont bien classées)"
      ],
      "metadata": {
        "id": "proetpgnHM7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 1.\n",
        "for t in range(5000):\n",
        "  # descente de gradient avec pytorch pour la classification binaire\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "XYBmJnhw3RRS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}